# Text_Project
Objective was to build a multilabel classification model that is capable of detecting different types of toxicity like threats, obscenity, insults and identity based hate.
Understanding the data by visualizing multiple plots and analyzing the relationship between classes.
Operated several text cleaning steps using RegEx and NLTK.
Vectorized the text using TF-IDF and applied multilabel logistic regression for classification.
